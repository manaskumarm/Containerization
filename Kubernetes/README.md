# Kubernetes
Kubernetes, also known as K8s, is an open source system for automating deployment, scaling, and management of containerized applications.

![image](https://github.com/manaskumarm/Containerization/assets/14363425/5dd202c1-810e-44cc-8ae6-9092e4aad6be)

# Components 
1Ô∏è‚É£ Control Plane Components: These components manage the cluster and make global decisions.

**1.1 API Server (kube-apiserver)**

Acts as the gateway for all Kubernetes operations.

Exposes the Kubernetes API (REST interface).

All requests from kubectl, helm, or external clients go through the API Server.

Ensures authentication, authorization, and admission control.

üîπ Check API Server logs: kubectl logs -n kube-system kube-apiserver-<node-name>

**1.2 Controller Manager (kube-controller-manager)**

Runs various background controllers to maintain the desired state.

Examples of controllers:

Node Controller ‚Üí Detects and replaces failed nodes.

Replication Controller ‚Üí Ensures the correct number of pod replicas are running.

Service Account Controller ‚Üí Manages service accounts and tokens.

üîπ Check Controller Manager logs: kubectl logs -n kube-system kube-controller-manager-<node-name>

**1.3 Scheduler (kube-scheduler)**

Assigns new pods to appropriate nodes based on:

Resource availability (CPU, memory)

Node taints & tolerations

Node affinity & anti-affinity

Uses various scheduling algorithms.

üîπ Check Scheduler logs:

kubectl logs -n kube-system kube-scheduler-<node-name>

**1.4 etcd (Key-Value Store)**

Stores cluster configuration & state (e.g., deployments, services, secrets).

Highly available and supports leader election.

Every change to Kubernetes objects is stored here.

üîπ Check etcd health:

ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 endpoint status --write-out=table

2Ô∏è‚É£ Worker Node Components

Worker nodes are where application containers actually run.

**2.1 Kubelet**

Agent running on each node.

Manages the lifecycle of pods (ensures containers are running).

Talks to the API Server and pulls container specs.

üîπ Check Kubelet logs: journalctl -u kubelet -f

2.2 Kube Proxy

Manages networking for services.

Maintains iptables or IPVS rules to route traffic inside the cluster.

Ensures communication between pods & services.

üîπ Check Kube Proxy logs: kubectl logs -n kube-system kube-proxy-<node-name>

**2.3 Container Runtime**

Runs containers inside pods.

Supported runtimes:

containerd (default in Kubernetes)
Docker
CRI-O
üîπ Check Container Runtime logs (containerd example):

sudo journalctl -u containerd -f

**3Ô∏è‚É£ Add-Ons (Optional but Important Components)**

**3.1 CoreDNS**

Provides internal DNS resolution.

Allows pods to communicate using service names (my-service.default.svc.cluster.local).
üîπ Check CoreDNS status:

kubectl get pods -n kube-system | grep coredns

3.2 Ingress Controller

Manages external HTTP/HTTPS traffic to services.

Supports path-based and host-based routing.

üîπ Example:

https://api.myapp.com/orders ‚Üí Routed to orders-service

https://api.myapp.com/users ‚Üí Routed to users-service

**3.3 Network Plugins (CNI)**

Controls pod networking.

Common CNIs:

Calico (network policies, BGP routing)

Flannel (simple overlay network)

Weave (automatic encryption)

üîπ Check CNI plugin logs:

kubectl get pods -n kube-system | grep calico

**3.4 Metrics Server**

Enables kubectl top commands.

Provides CPU and memory usage metrics.

üîπ Install Metrics Server:

kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml


# Commands
![image](https://github.com/user-attachments/assets/8e580d9e-7840-4c2a-96ba-90c1c5ed5a42)



 # Debugging
**A. Pod & Container Details**

Pod name, namespace

Pod status (Running, Pending, CrashLoopBackOff, OOMKilled, etc.)

Container logs and events

Resource limits (CPU, Memory)

**B. Service & Network Details**

Service type (ClusterIP, NodePort, LoadBalancer, ExternalName)

DNS resolution (service-name.namespace.svc.cluster.local)

Network policies

Kubernetes API server & connectivity

**C. Node Details**
Node status (Ready, NotReady, Unschedulable)

Disk, CPU, memory usage

Network connectivity

Kernel logs for failures

****Commands****
**A. Check Pod & Container Status**

kubectl get pods -A -o wide   # Get all pods with node info

kubectl describe pod <pod-name> -n <namespace>   # Detailed events and pod status

kubectl logs <pod-name> -c <container-name> -n <namespace>   # Check container logs

kubectl logs <pod-name> --previous   # Get logs of the crashed container

kubectl exec -it <pod-name> -n <namespace> -- sh   # Get shell inside the container

üëâ If a pod is stuck in CrashLoopBackOff, check logs and events.

**B. Check Node Status**

kubectl get nodes -o wide    # Get all nodes

kubectl describe node <node-name>   # Check node conditions, taints

kubectl top node   # Check CPU/memory usage

dmesg | tail -50   # Check kernel logs for node-level issues

üëâ If a node is NotReady, check network or resource issues.

**C. Check Service & Network Issues**

kubectl get svc -A   # List all services

kubectl describe svc <service-name> -n <namespace>   # Check service endpoints

kubectl get endpoints <service-name> -n <namespace>   # Ensure the service has endpoints

kubectl exec -it <pod-name> -- curl http://<service-name>:<port>   # Test connectivity from a pod

üëâ If a service has no endpoints, check if the pod labels match the service selector.

**D. Check Network Policies & DNS**

kubectl get networkpolicy -A   # List all network policies

kubectl describe networkpolicy <policy-name> -n <namespace>   # Check rules

kubectl exec -it <pod-name> -- nslookup <service-name>   # Check DNS resolution

kubectl get pods -n kube-system | grep coredns   # Check CoreDNS status

üëâ If DNS is failing, restart CoreDNS and verify network policies.

**E. Debugging Kubernetes API & Scheduling Issues**

kubectl get events --sort-by=.metadata.creationTimestamp   # List recent events

kubectl get pods --field-selector=status.phase=Pending   # Find pods stuck in Pending

kubectl describe pod <pod-name>   # Check pod scheduling issues

kubectl get deployments -A   # Ensure deployments are healthy

üëâ If a pod is Pending, check events, taints, and resource constraints.

**F. Debugging CNI & Network Plugin Issues**

kubectl get pods -n kube-system | grep calico  # If using Calico

kubectl get pods -n kube-system | grep weave   # If using Weave

kubectl get pods -n kube-system | grep flannel # If using Flannel

iptables -L -v -n    # Check if iptables is blocking traffic

üëâ If network communication is blocked, check CNI logs and iptables.

****Metrics****
**A. Container Logs**

kubectl logs <pod-name> (Get logs of running containers)

kubectl logs <pod-name> --previous (Get logs of crashed containers)

kubectl exec -it <pod-name> -- cat /var/log/app.log (Check custom application logs)

**B. Node & System Logs**

Kernel Logs:

journalctl -u kubelet -n 50

dmesg | tail -50

Kubelet Logs:

cat /var/log/kubelet.log

**C. Cluster Events**

kubectl get events --sort-by=.metadata.creationTimestamp

üëâ Helps in tracking failures, OOM kills, and scheduling issues.

**If you want quick insights, try:**

kubectl-debug: Debug pods interactively

kubectl debug pod/<pod-name> -it --image=busybox

stern: Real-time log monitoring of multiple pods(need to install manually)

stern <pod-name>

k9s: Interactive Kubernetes CLI tool

k9s

# Best Practices

**Use Multi-Master Setup**

Run at least 3 control plane nodes for redundancy.

Distribute nodes across multiple availability zones (AZs).

**Use etcd Backups**

Regularly back up etcd to prevent data loss.

Example backup command:  ETCDCTL_API=3 etcdctl snapshot save backup.db

‚úÖ Separate Control Plane & Worker Nodes

Keep API server, etcd, and controllers isolated from worker nodes.

**Use Role-Based Access Control (RBAC)**

Grant least privilege access.

Check permissions: kubectl get roles,rolebindings --all-namespaces

**Restrict API Access**

Disable anonymous access to the API server: --anonymous-auth=false

Use OIDC authentication (e.g., AWS IAM, Azure AD).

**Enable Network Policies**

Restrict pod communication using NetworkPolicy

**Scan Images for Vulnerabilities**

Use Trivy, Aqua, or Snyk for container security scanning

**Use Secrets Properly**

Store secrets in Kubernetes Secrets (not ConfigMaps!).

Encrypt secrets using: --encryption-provider-config=/etc/kubernetes/encryption-config.yaml

**Use Requests & Limits for Pods**

Prevent a single pod from consuming all CPU/memory

**Enable Horizontal Pod Autoscaler (HPA)**

Automatically scale pods based on CPU or memory usage.

**Enable Cluster Autoscaler**

Automatically add or remove worker nodes based on demand.

--cluster-autoscaler-enabled=true

**Centralized Logging**

Use Fluentd, ELK (Elasticsearch + Logstash + Kibana), Loki, or EFK.

Stream logs to external storage instead of relying on kubectl logs.

**Use Prometheus & Grafana**

Collect metrics using Prometheus.

Visualize dashboards using Grafana.

**Monitor Kubernetes Events**

Use New Relic, Datadog, or Azure Monitor for real-time event tracking.

**Use Ingress Controllers for External Traffic**

Use Nginx Ingress, Traefik, or AWS ALB Ingress.

**Enable Service Mesh for Microservices**

Use Istio or Linkerd for secure communication between microservices.

**Optimize DNS Resolution**

Use ndots:5 in DNS settings to improve resolution speed.

**Use Persistent Volumes (PV) & Persistent Volume Claims (PVC)**

Ensure data persistence for databases.

**Regularly Backup Persistent Volumes**

Use Velero for disaster recovery

**Use Rolling Updates (Avoid Downtime)**

Deploy apps gradually instead of stopping all pods

**Use Canary Deployments for Testing**

Deploy small batches of new code before full rollout.

**Use Helm for Deployments**

Helm simplifies app deployment using templates. helm install my-app ./my-app-chart

